{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7cd3a024-5f12-47ce-8511-c2bfae262628",
   "metadata": {},
   "source": [
    "# Tutorial 2-a: Automatic Feature Extraction/Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed665b16-22c8-4a4d-b4db-0837264fb837",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58a99b7c-2540-4862-bcca-315eeb1c0803",
   "metadata": {},
   "source": [
    "### Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21e5412c-eb3a-416a-81ff-ce5f77a0df88",
   "metadata": {},
   "source": [
    "In this notebook, we will extract/engineer features using a deep learning method called autoencoder.\n",
    "The input and the output of this method will be the galaxy images. An autoencoder is an artificial neural network with a symmetric structure which is trained to reconstruct its input onto the output layer. The output of the first half of the network represents an encoding of the input data. ([source](https://arxiv.org/abs/2206.06165))."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8030153b-d68e-4f25-8774-4b9e4bb5bfef",
   "metadata": {},
   "source": [
    "First, we import some libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe9d5526-086d-4d0e-b546-e81af265749a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt # for plotting data/graphs\n",
    "import numpy as np # For handling N-DIMENSIONAL ARRAYS\n",
    "\n",
    "import tensorflow as tf #An end-to-end machine learning platform, focusing on training deep learning models\n",
    "from tensorflow.keras import layers, losses # Implementation of the Keras API, the high-level API of TensorFlow.\n",
    "from tensorflow.keras.models import Model #This displays graphs \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20c7b065-2cd2-4d88-8329-a7b0e9591e1a",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c7a52a2-6542-4535-9aad-0782ed0eb4a4",
   "metadata": {},
   "source": [
    "### Reading in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "700ba1a6-c0cd-4bb9-ae83-74143f138397",
   "metadata": {},
   "outputs": [],
   "source": [
    "from galaxy_mnist import GalaxyMNISTHighrez\n",
    "\n",
    "dataset_train = GalaxyMNISTHighrez(\n",
    "    root='data_import/data',\n",
    "    download=True,\n",
    "    train=True  # by default, or False for canonical test set\n",
    ")\n",
    "# for the testing data\n",
    "dataset_test = GalaxyMNISTHighrez(\n",
    "    root='data_import/data',\n",
    "    download=True,\n",
    "    train=False  # by default, or False for canonical test set\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4639a4d-6649-48e5-8fec-47d8026828fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining the training and testing labels and image samples\n",
    "images_train = dataset_train.data\n",
    "images_test = dataset_test.data\n",
    "labels_train = dataset_train.targets\n",
    "labels_test = dataset_test.targets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55f4d509-8977-4f8d-a158-8a0bfc75db0b",
   "metadata": {},
   "source": [
    "### Pre-processing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6decf49-9a17-43b2-b659-6a429440326b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from source.pre import pre_processing #  A predefined function to pre-process the data as we did in tutorial 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2b9da92-41d1-41b7-a888-593598261aed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pre-processing(data, size) function takes two arguments\n",
    "# 1. data: the data to be processed\n",
    "# 2. The size for which the data needs to be reduced.\n",
    "images_trainPre = pre_processing(images_train, 56)\n",
    "images_testPre = pre_processing(images_test, 56)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "887d6bae-5885-4ce3-83d7-74dbdaeb8b34",
   "metadata": {},
   "outputs": [],
   "source": [
    "images_trainPre.shape # the shape of the training data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba698cf5-b955-43a1-8dcd-e97f4088e2de",
   "metadata": {},
   "source": [
    "Displaying images after pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bb62536-7817-4f05-9110-263a0f57da10",
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = 1\n",
    "columns = 5\n",
    "for j in range(len(GalaxyMNISTHighrez.classes)):\n",
    "    fig = plt.figure(figsize=(8, 8))# Figure is 8 inches by 8 inches\n",
    "    for i in range (columns):    # Create images in each column\n",
    "        train_image = images_trainPre[(labels_train == j)][i]\n",
    "        fig.add_subplot(rows, columns, i+1)\n",
    "        plt.imshow(train_image*255,cmap='gray', vmin=0, vmax=255) \n",
    "                            # we have to multiply the image by 255 to restore the original values\n",
    "    print(\"label: \"+str(GalaxyMNISTHighrez.classes[j]))\n",
    "    plt.tight_layout()\n",
    "    plt.show() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7444a5c0-dd53-49df-bcd0-fa56e2f874d3",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12cd1b55-87ec-4794-925a-c9bcf919c35f",
   "metadata": {},
   "source": [
    "## Shallow Autoencoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccc59a2f-14d3-47db-90d0-65454e41db44",
   "metadata": {},
   "source": [
    "Now we will train the autoencoder nural network on the data that we pre-processed. The original code can be found [here](https://www.tensorflow.org/tutorials/generative/autoencoder)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91913044-6f3c-475f-8fc8-c6ce791b5488",
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_dim = 64 # the number of features to be encoded, this can change \n",
    "num, length, width  = images_trainPre.shape\n",
    "# need to document how excatly it works\n",
    "\n",
    "class Autoencoder(Model):\n",
    "  def __init__(self, latent_dim):\n",
    "    super(Autoencoder, self).__init__()\n",
    "    self.latent_dim = latent_dim   \n",
    "    self.encoder = tf.keras.Sequential([\n",
    "      layers.Flatten(),\n",
    "      layers.Dense(latent_dim, activation='relu'),\n",
    "    ])\n",
    "    self.decoder = tf.keras.Sequential([\n",
    "      layers.Dense(length*width, activation='sigmoid'),\n",
    "      layers.Reshape((length, width))\n",
    "    ])\n",
    "\n",
    "  def call(self, x):\n",
    "    encoded = self.encoder(x)\n",
    "    decoded = self.decoder(encoded)\n",
    "    return decoded\n",
    "\n",
    "shallow_model = Autoencoder(latent_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "395a790d-e822-4931-aa81-a08dd2139d03",
   "metadata": {},
   "outputs": [],
   "source": [
    "shallow_model.compile(optimizer='adam', loss=losses.MeanSquaredError())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74973b4d-eed4-44c5-a4b9-56f64a8098ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "early_stopping = EarlyStopping(patience=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14142d42-8a62-4b58-9da4-4ae5cf6eb163",
   "metadata": {},
   "source": [
    "`EarlyStopping()` has a few options and by default:\n",
    " - `monitor='val_loss'`: to use validation loss as performance measure to terminate the training.\n",
    "- `patience=0`: is the number of epochs with no improvement. The value 0 means the training is terminated as soon as the performance measure gets worse from one epoch to the next."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0da6b051-ff28-40d8-89da-1707effe9a0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "shallow_model.fit(np.array(images_trainPre), np.array(images_trainPre),\n",
    "                epochs=50,\n",
    "                shuffle=True,\n",
    "                validation_data=(np.array(images_trainPre), np.array(images_trainPre)), callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9d8d8c7-be81-4aec-a199-f581a8086d59",
   "metadata": {},
   "source": [
    "You can notice that runing this code is quite fast, this is becuase the model is too shallow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dffabd2d-2f3d-4c99-b653-4310ff871106",
   "metadata": {},
   "outputs": [],
   "source": [
    "shallow_model.save(\"./shallowModel_save\") # saving the model (shallow)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "124ae8e9-3ec3-42e1-bcd1-ccc403c6e823",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_imgs = shallow_model.encoder(images_testPre).numpy()\n",
    "decoded_imgs = shallow_model.decoder(encoded_imgs).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ae370e2-1298-44f9-9116-4ff3fb40bddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(decoded_imgs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4bfc53b-ee82-4e86-95b8-1db0953c618d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "rows = 1\n",
    "columns = 5\n",
    "for j in range(len(GalaxyMNISTHighrez.classes)):\n",
    "    fig = plt.figure(figsize=(8, 8))# Figure is 8 inches by 8 inches\n",
    "    for i in range (columns):    # Create images in each column\n",
    "        test_image = images_testPre[(labels_test == j)][i]\n",
    "        fig.add_subplot(rows, columns, i+1)\n",
    "        plt.imshow(test_image*255,cmap='gray', vmin=0, vmax=255) \n",
    "                            # we have to multiply the image by 255 to restore the original values\n",
    "    print(\"Original: \"+str(GalaxyMNISTHighrez.classes[j]))\n",
    "    plt.tight_layout()\n",
    "    plt.show() \n",
    "    \n",
    "    fig = plt.figure(figsize=(8, 8))# Figure is 8 inches by 8 inches\n",
    "    for i in range (columns):    # Create images in each column\n",
    "        test_image = decoded_imgs[(labels_test == j)][i]\n",
    "        fig.add_subplot(rows, columns, i+1)\n",
    "        plt.imshow(test_image*255,cmap='gray', vmin=0, vmax=255) \n",
    "                            # we have to multiply the image by 255 to restore the original values\n",
    "    print(\"Reconstructed: \"+str(GalaxyMNISTHighrez.classes[j]))\n",
    "    plt.tight_layout()\n",
    "    plt.show() \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dc42e49-a2a5-4b60-bb7b-b6b24c716ee8",
   "metadata": {},
   "source": [
    "**Exercise 1:** Which classes do you think will be confused with the others?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee3ebe2f-aa22-4283-84d4-1bf2adb00237",
   "metadata": {},
   "outputs": [],
   "source": [
    "### -- Answer here --\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2d10703-99a6-4cda-956a-90593104d410",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07ed9483-f19e-468c-a27b-59024b7ca62d",
   "metadata": {},
   "source": [
    "### Deep convolutional autoencoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39ea3b29-96de-4813-abc3-daf9a5591bd5",
   "metadata": {},
   "source": [
    "A convolutional autoencoder makes use of convolutional neural network mechanisms to reduce and engineer the images. Now let us try a more complicated model and notice the difference, time and image quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6ea26ce-78ce-4870-ab1b-968ac82953b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GalaxyEncoder(Model):\n",
    "    def __init__(self):\n",
    "        super(GalaxyEncoder, self).__init__()\n",
    "        self.encoder = tf.keras.Sequential ([\n",
    "            layers.InputLayer(input_shape=(56,56,1)),\n",
    "            layers.Conv2D(16, (3,3), 1, padding=\"same\", activation=\"relu\"),\n",
    "            layers.MaxPool2D((2,2), padding=\"same\", strides=2),\n",
    "            layers.Conv2D(8, (3,3), 1, padding=\"same\", activation=\"relu\"),\n",
    "            layers.MaxPool2D((2,2), padding=\"same\", strides=2),\n",
    "            layers.Flatten()\n",
    "        ])\n",
    "        self.decoder = tf.keras.Sequential ([\n",
    "            layers.InputLayer(input_shape=(1568)),\n",
    "            layers.Reshape((14, 14, 8)),\n",
    "            layers.UpSampling2D((2,2)),\n",
    "            layers.Conv2DTranspose(8, (3,3), 1, padding=\"same\", activation=\"relu\"),\n",
    "            layers.UpSampling2D((2,2)),\n",
    "            layers.Conv2DTranspose(16, (3,3), 1, padding=\"same\", activation=\"relu\"),\n",
    "            layers.Conv2D(1, (3,3), 1, padding=\"same\", activation=\"sigmoid\")\n",
    "        ])\n",
    "\n",
    "    def call(self, x):\n",
    "        encoded = self.encoder(x)\n",
    "        decoded = self.decoder(encoded)\n",
    "        return decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29c52cf9-7aa9-4252-8610-09682743fd75",
   "metadata": {},
   "outputs": [],
   "source": [
    "deep_model = GalaxyEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55ecbf04-e17d-4061-9df3-f43868219dc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "deep_model.compile(optimizer='sgd', loss='mse')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9764d0b-0db8-4312-8c43-f79da8843f44",
   "metadata": {},
   "outputs": [],
   "source": [
    "deep_model.build((None, 56,56,1))\n",
    "deep_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae50c998-1d1d-422d-96b2-3565c9a16cb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = EarlyStopping(patience=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c422951-327b-4b5b-a549-a821bc9964ec",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "deep_model.fit(np.array(images_trainPre), np.array(images_trainPre),\n",
    "                epochs=40,\n",
    "                shuffle=True,\n",
    "                validation_data=(np.array(images_trainPre), np.array(images_trainPre)), callbacks=[early_stopping])\n",
    "# start with the 2nd tut instead of waiting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fb75688-835a-455e-b24d-abf4b39835f8",
   "metadata": {
    "tags": []
   },
   "source": [
    "**Exercise 2:** Save the deep model for later use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "944ef3f6-1ae9-447c-a4b0-3b6f428f1a63",
   "metadata": {},
   "outputs": [],
   "source": [
    "### -- Code here --\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab7de94a-6db4-4294-bfc6-a0de5dc270fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_imgs = deep_model.encoder(images_testPre).numpy()\n",
    "decoded_imgs = deep_model.decoder(encoded_imgs).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3a4f824-53aa-435b-a3c5-b39b36799e23",
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = 1\n",
    "columns = 5\n",
    "for j in range(len(GalaxyMNISTHighrez.classes)):\n",
    "    fig = plt.figure(figsize=(8, 8))# Figure is 8 inches by 8 inches\n",
    "    for i in range (columns):    # Create images in each column\n",
    "        test_image = images_testPre[(labels_test == j)][i]\n",
    "        fig.add_subplot(rows, columns, i+1)\n",
    "        plt.imshow(test_image*255,cmap='gray', vmin=0, vmax=255) \n",
    "                            # we have to multiply the image by 255 to restore the original values\n",
    "    print(\"Original: \"+str(GalaxyMNISTHighrez.classes[j]))\n",
    "    plt.tight_layout()\n",
    "    plt.show() \n",
    "    \n",
    "    fig = plt.figure(figsize=(8, 8))# Figure is 8 inches by 8 inches\n",
    "    for i in range (columns):    # Create images in each column\n",
    "        test_image = decoded_imgs[(labels_test == j)][i]\n",
    "        fig.add_subplot(rows, columns, i+1)\n",
    "        plt.imshow(test_image*255,cmap='gray', vmin=0, vmax=255) \n",
    "                            # we have to multiply the image by 255 to restore the original values\n",
    "    print(\"Reconstructed: \"+str(GalaxyMNISTHighrez.classes[j]))\n",
    "    plt.tight_layout()\n",
    "    plt.show() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11675dbb-282c-454e-82c1-f847c21c3358",
   "metadata": {},
   "source": [
    "**Exercise 3:** Visually how do the reconstructed images from the deep model compare to the shallow one?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee650656-96a0-4bfe-bff5-3588f25bf02c",
   "metadata": {},
   "outputs": [],
   "source": [
    "### -- Answer here --\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bdb4088-b3c8-42b2-a39f-502170540cbf",
   "metadata": {},
   "source": [
    "I think including the time in thier analysis will be very good."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7861c799-f263-46b9-b8c4-f0767b65febc",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca031aad-2a6d-42a2-bc71-ce97eabd391c",
   "metadata": {},
   "source": [
    "#### **_Saving data for later use_**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccaddef7-3663-41bb-8f6c-b6d1d26cae85",
   "metadata": {},
   "source": [
    "We can save the data so that we can call it up again in subsequent notebooks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c80fb440-3e58-4562-adc3-41e001c18acc",
   "metadata": {},
   "outputs": [],
   "source": [
    "%store images_trainPre\n",
    "%store images_testPre\n",
    "%store labels_train\n",
    "%store labels_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04993e78-0899-48f9-b9b3-abf6603ce9d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc36b6d3-5e3b-4215-b196-5827c7618b58",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('galaxy')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "c3e388211946b675a28e5b4f6d2cc369da4c7956e6fa8042622e53f8667b4b0e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
