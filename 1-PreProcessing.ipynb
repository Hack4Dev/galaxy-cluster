{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "adbff74c-bad7-48db-8c06-46c8ae5d06e7",
   "metadata": {},
   "source": [
    "# Tutorial 1: Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a03f544f-0f47-48c8-97c2-0a3122652135",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "382b72f0-283f-428b-bc77-55403b690607",
   "metadata": {},
   "source": [
    "### Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a6e5406-2ec0-42b3-bcef-8c3856cfb7ac",
   "metadata": {},
   "source": [
    "Welcome! This tutorial will show you how to visualise and preprocess astronomical data using python. From this tutorial, you will learn the following:\n",
    "\n",
    "1. How to download astronomical data\n",
    "2. How to read and visualise data\n",
    "3. How to preprocess imagery data\n",
    "\n",
    "The data [GalaxyMNIST](https://github.com/mwalmsley/galaxy_mnist) contains 10,000 images of galaxies (either 3x64x64 or 3x224x224), labelled by Galaxy Zoo volunteers as belonging to one of four morphology classes, where the classes are:\n",
    "\n",
    "0. smooth and round\n",
    "1. smooth and cigar-shaped\n",
    "2. edge-on-disk\n",
    "3. unbarred spiral\n",
    "\n",
    "The galaxies are selected from `Galaxy Zoo DECaLS Campaign` A (GZD-A). The images are shown to volunteers on Galaxy Zoo for them to classify. For each image, at least 17 people were asked the necessary questions, and at least half of them must have answered with the given class. The class labels are, therefore, much more confident than, for example, simply labelling with the most common answer to some question. For more info, visit this [link](https://github.com/mwalmsley/galaxy_mnist)\n",
    "\n",
    "\n",
    "Labelling data is a big topic in machine learning. Labelled data allow us to use supervised machine learning tools to train on labelled data and classify unlabeled ones. However, labelling data can be costly. Scientists have been trying to figure out a way to label data, but the easiest is that we can depend on human knowledge to label data like the `Galaxy Zoo DECaLS Campaign`.  However, unlabeled data can also be of some benefit if analyzed with the right tools, like unsupervised machine learning. Those tools allow us to explore (find patterns) and cluster the data, leading to discoveries in the data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9861171f-09cb-4087-8a38-c5efdcc626b6",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e74ab73-1be1-4063-b552-dc26466d6390",
   "metadata": {},
   "source": [
    "### Downloading data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7505e73e-8fe3-4f89-9299-168c52974f4a",
   "metadata": {},
   "source": [
    "First, let us call the python script that will let us download the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c0b7a79-6210-47e9-a88e-050230bae66c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/mwalmsley/galaxy_mnist\n",
    "from galaxy_mnist import GalaxyMNISTHighrez"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f0a8f9b-705a-4289-a0a3-5f953f3bcad6",
   "metadata": {},
   "source": [
    "'GalaxyMNISTHighrez' class has the follwing attributes: \n",
    " - `root`: Specifing the dir to download the data\n",
    " - `download:` A boolean value, `True` to download the images\n",
    " - `train:` A boolean value, `True` to assign the just the training data, `False` will assign just the testing data. \n",
    "   - `Notice:` The data has a fixed 80/20 train/test division."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0e526b1-fa23-4b61-be7f-e0b69f2fe157",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for the training data\n",
    "dataset_train = GalaxyMNISTHighrez(\n",
    "    root='data_import/data',\n",
    "    download=True,\n",
    "    train=True  # by default True, or False for canonical test set\n",
    ")\n",
    "# for the testing data\n",
    "dataset_test = GalaxyMNISTHighrez(\n",
    "    root='data_import/data',\n",
    "    download=True,\n",
    "    train=False  # by default True, or False for canonical test set\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c67448b-a84d-4d3b-8c20-4be1c8707f81",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0811f16c-41f5-4576-8346-489b81daeaf5",
   "metadata": {},
   "source": [
    "### Reading data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee8bd2ee-cda3-4eea-a685-45ea0b6ebd7c",
   "metadata": {},
   "source": [
    "First, let us read inputs `images` and outputs `labels` into two seperate variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f1681f5-5382-4179-b0f1-b8932018c8e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "images_train = dataset_train.data\n",
    "labels_train = dataset_train.targets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afc89ec2-cfed-4756-b595-4ab69eb1bb56",
   "metadata": {},
   "source": [
    "Now check the shape of the two datasets (training, and testing)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d453cced-95bd-498a-acc8-83da58636e78",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Shape of the input (training) \"+str(images_train.shape)+ \", type: \"+ str(images_train.dtype))\n",
    "print(\"Shape of the output (training) \"+str(labels_train.shape)+ \", type: \"+ str(labels_train.dtype))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9453e0f1-96c5-4fc6-8d7c-98447cf9893d",
   "metadata": {},
   "source": [
    "We notice the following:\n",
    " 1. The input data has 8000 samples with 3 channels, which stands for `rgb` colors, where each sample has a size of 224.\n",
    " 2. the output is a one-dimensional array which contains the labels of the samples. Each label is 0,1,2,3 according to the categories listed in the first cell above. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f52a7bbd-b5d3-4fe3-b8f2-6d62d667dacb",
   "metadata": {},
   "source": [
    "**Exercise 1:**\n",
    "Store the testing set inputs and outputs into two different variables, and display their shape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a886e8a-9fab-4d24-8011-c74372955262",
   "metadata": {},
   "outputs": [],
   "source": [
    "### -- Code here --\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3047b3ef-da99-4da4-9aef-34fdb1fad04b",
   "metadata": {},
   "source": [
    "Now, let's check the frequency of the labels/output, but first let us print them out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd4970e7-3b81-4593-8e82-3f203ad94b96",
   "metadata": {},
   "outputs": [],
   "source": [
    "GalaxyMNISTHighrez.classes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6030ce59-c41b-4509-a591-9033e2035216",
   "metadata": {},
   "source": [
    "   **Where**:\n",
    "   - 0: `smooth_round`,\n",
    "   - 1: `smooth_cigar`,\n",
    "   - 2: `edge_on_disk`,\n",
    "   - 3: `unbarred_spiral`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8112e9c-3754-4287-b5a4-659fdc871f9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # For handling N-DIMENSIONAL ARRAYS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fa1f9c0-d4ee-4932-9b03-bc30615fec6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(labels_train)\n",
    "labels_trainNP = np.array(labels_train)\n",
    "unique_labels, count_labels = np.unique(labels_trainNP, return_counts=True)\n",
    "print(unique_labels, count_labels )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b03ac782-2c19-4550-83f8-12932b3be7c3",
   "metadata": {},
   "source": [
    "### Data visualisation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2980958-3242-42f5-93f4-9a02128c1a33",
   "metadata": {},
   "source": [
    "We can also try to visualise label frequencies in a bar graph. To do this, we need the `pyplot' graphics package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d860a861-e2d8-41ee-a73f-a62a5df5f0be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt #This displays graphs once they have been created"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93ceeebe",
   "metadata": {},
   "source": [
    "The code for plotting is below. To make a clear display, we replace class labels with the actual class names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77a88dc3-0f41-4cbf-81b8-73fd13cb5f88",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.bar(range(len(unique_labels)), count_labels, align='center')\n",
    "plt.xticks(range(len(unique_labels)), GalaxyMNISTHighrez.classes)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4b030ef-042b-4dc4-aa0b-78ccb6f84a96",
   "metadata": {},
   "source": [
    "**Exercise 2:**\n",
    "Count the class frequencies for the testing data, and visualise using a histogram."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f80ca70-7f59-4f2e-803a-6dbf2f45039f",
   "metadata": {},
   "outputs": [],
   "source": [
    "### -- Code here --\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2437829e-5fa1-4096-b53f-7f93afa15d97",
   "metadata": {},
   "source": [
    "Now let us take a look at the images of the different galaxy shapes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56b8e085-fbe0-485e-8826-00f84ed53a7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image #  PIL is the Python Imaging Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2e6dc8f-2107-4c28-8297-4f71c46f8678",
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = 1\n",
    "columns = 5\n",
    "for j in range(len(GalaxyMNISTHighrez.classes)):\n",
    "    fig = plt.figure(figsize=(8, 8))# Figure is 8 inches by 8 inches\n",
    "    for i in range (columns):    # Create images in each column\n",
    "        train_image = images_train[(labels_train == j)][i]\n",
    "        fig.add_subplot(rows, columns, i+1)\n",
    "        plt.imshow(np.array(train_image).transpose(1, 2, 0))\n",
    "    print(\"label: \"+str(GalaxyMNISTHighrez.classes[j]))\n",
    "    plt.tight_layout()\n",
    "    plt.show() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bff98eb7-d589-4c01-a8d2-c6e4f7cb08bc",
   "metadata": {},
   "source": [
    "The resolution of this dataset does not seem to be good, `smooth cigar` and `edge_on_disk` kind of look like each other, which will give us problems later on when performing classification or clustering."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef633f20-c7fe-456a-bca4-e0f63a07e1fb",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35a2e4fd-e10a-473c-a754-26fe1859a148",
   "metadata": {},
   "source": [
    "### Data preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5a5fbea-1d8f-4983-898d-f610a09d60b8",
   "metadata": {},
   "source": [
    "Classical machine learning usually requires the data to undergo extensive preprocessing before it is fit for training (e.g. feature extraction, optimization, ..). For each layer, many different algorithms may be used. \n",
    "\n",
    "On the other hand, deep learning models with enough data are often referred to as End-to-End learning models ([E2E](https://towardsdatascience.com/e2e-the-every-purpose-ml-method-5d4f20dafee4)), since they can extract information from raw data.\n",
    "\n",
    "In the following tutorial, we will use an autoencoder (deep learning) model to extract features. In theory, we can feed the raw data into the autoencoder without any preprocessing. However, in practice this greatly increases the computation time required. In this tutorial series we need to train the models in a reasonable time so that we can bring the idea across. The issue is especially important because use of raw data optimally requires hyperparameter tuning, which is even more time consuming.\n",
    "\n",
    "However, preprocessing has a caveat. We need to make sure that the preprocessing does not lose any useful information. How can we verify this? In our case, since the data is imagery data we can examine the preprocessed images visually. If we can still easily classify them, then we can conclude that the preprocessing is effective.\n",
    "\n",
    "The pipeline we have described above is just one possibility. Participants are encouraged to explore alternatives.\n",
    "\n",
    "In this tutorial, we will try to reduce the complexity of the data by doing the following:\n",
    "   - Convert images to grayscale (reduces data by a factor  of 3)\n",
    "   - Reduce the size of the image by a factor of 4 @@@ InterpolationMode.BILINEAR @@@ Is this okay?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5933e22-fe04-40de-8354-ee15f34bbc96",
   "metadata": {},
   "source": [
    "We begin with conversion to grayscale, following this [tutorial](https://www.tutorialspoint.com/pytorch-how-to-convert-an-image-to-grayscale) from [tutorialspoint.com](https://www.tutorialspoint.com)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00708585-0753-43c2-b500-6320e25f493a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.transforms as transforms #Transforms are for common image transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f713795-caae-463e-a2d7-02baf84f32c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "images_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b16100fa-e332-4a32-937d-cfd3b7f8db06",
   "metadata": {},
   "source": [
    "We can see that the original image size has three channels which stand for the RGB colours, now let us perfom the `greyscalling`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c37cd306-8d90-4a3e-8777-e20ed2c42bed",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformGrey = transforms.Grayscale()\n",
    "images_trainGrey = transformGrey(images_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d97ed52-62c4-4b8f-aa95-59182b7cd51d",
   "metadata": {},
   "source": [
    "Now let us check the size of the tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c518854-5fb5-4993-9dc7-2a2a0700bfe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "images_trainGrey.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da834b13-6b0c-4b02-9972-c8f97430cab7",
   "metadata": {},
   "source": [
    "we can see the number of channels went down from 3 to 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5f92a8b-3463-42d0-bbca-8ebe55a9c163",
   "metadata": {},
   "source": [
    "**Exercise 3:**\n",
    "Visualise the grayscale images for all classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91ef7e7e-7b0b-4a95-b45e-4b7fda8c90dd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "### -- Code here__\n",
    "\n",
    "rows = 1\n",
    "columns = 5\n",
    "for j in range(len(GalaxyMNISTHighrez.classes)):\n",
    "    fig = plt.figure(figsize=(8, 8))# Figure is 8 inches by 8 inches\n",
    "    for i in range (columns):    # Create images in each column\n",
    "        train_image = images_trainGrey[(labels_train == j)][i]\n",
    "        fig.add_subplot(rows, columns, i+1)\n",
    "        plt.imshow(np.array(train_image).transpose(1, 2, 0) ,cmap='gray', vmin=0, vmax=255)\n",
    "    print(\"label: \"+str(GalaxyMNISTHighrez.classes[j]))\n",
    "    plt.tight_layout()\n",
    "    plt.show() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45e0c702-ec9a-4838-97f2-dbd560db0e2c",
   "metadata": {},
   "source": [
    "We can notice that visually that nothing changed much from the original data. However, we reduced the complexity of the data by a favour of 3, which is enormous!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49f23918-79d1-477b-9e63-0ed5dda9b2b4",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### b- [Size reduction](https://www.tutorialspoint.com/pytorch-how-to-resize-an-image-to-a-given-size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e01eeee-03d1-4b21-9726-ad7fddc4ebf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformResize = transforms.Resize(56)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d591387e-b384-4c44-b293-65cacec4c41f",
   "metadata": {},
   "source": [
    "Now let us reduce the image, we will reduce it on the grayscale images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42e16e25-1fc3-4931-8245-38a6a248567e",
   "metadata": {},
   "outputs": [],
   "source": [
    "images_trainResized = transformResize(images_trainGrey)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63563091-5140-45d5-aad3-f5933ba6dd14",
   "metadata": {},
   "source": [
    "now let us check the size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27581f1b-e728-4e07-b6e3-eda072969701",
   "metadata": {},
   "outputs": [],
   "source": [
    "images_trainResized.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b96c7abc-b630-4fb7-ba86-4d06c67e9119",
   "metadata": {},
   "source": [
    "**Exercise 4:**\n",
    "Visualise the resized images for all classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c6228e9-9d8e-49d3-9760-b9794393590f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#___ Code here___\n",
    "\n",
    "rows = 1\n",
    "columns = 5\n",
    "for j in range(len(GalaxyMNISTHighrez.classes)):\n",
    "    fig = plt.figure(figsize=(8, 8))# Figure is 8 inches by 8 inches\n",
    "    for i in range (columns):    # Create images in each column\n",
    "        train_image = images_trainResized[(labels_train == j)][i]\n",
    "        fig.add_subplot(rows, columns, i+1)\n",
    "        plt.imshow(np.array(train_image).transpose(1, 2, 0) ,cmap='gray', vmin=0, vmax=255)\n",
    "    print(\"label: \"+str(GalaxyMNISTHighrez.classes[j]))\n",
    "    plt.tight_layout()\n",
    "    plt.show() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95ce2ec6-c0b5-485f-91ab-da9442e6d4fc",
   "metadata": {},
   "source": [
    "##### **_End of the pre-processing pipeline_**\n",
    "\n",
    "Now the above pre-processing is not the only way where we can reduce the features, the following can also be done:\n",
    "1. Cropping images away from the centre\n",
    "2. Image segmentation, maybe to remove background noise (Deep learning can be used for this)\n",
    "3. ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a5773d3-aa06-490c-93f2-c5ca52476980",
   "metadata": {},
   "source": [
    "### Normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c35d031-dc9a-4642-ab6c-99f4a134adb9",
   "metadata": {},
   "source": [
    "Now we will simply try to devide the pixel values by 255. Where the goal is to transform features to be on a similar scale ([source](https://developers.google.com/machine-learning/data-prep/transform/normalization))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d64f75cf-e7a0-4550-93b8-169fbab9d792",
   "metadata": {},
   "outputs": [],
   "source": [
    "images_trainPre = images_trainResized/255"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "885b96e0-2c4d-4848-96e4-b4bfbc25a3cd",
   "metadata": {},
   "source": [
    "Now let us check the values before and after the nomalisatiom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5699e7f-c2e7-484d-b68b-d638735dbc01",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(images_trainResized[0][0][0])\n",
    "print(images_trainPre[0][0][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "321f4c8b-4269-4f37-93eb-2d995c246274",
   "metadata": {},
   "source": [
    "**Exercise 5**: Perform the pre-processing pipeline but on the testing set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6238447f-95bc-4c42-812b-32ba8f51b88c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#___ Code here___\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dff1771-5ae0-4903-893b-258a96ea2b9f",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49edf65d-e9ca-497a-a0fa-e4932faa1d1f",
   "metadata": {},
   "source": [
    "### **_End of Tutorial 1_**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbf20dee-fc66-4396-affd-6f750bcd31e2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hackathon",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "vscode": {
   "interpreter": {
    "hash": "7dc42d555f8d6ccc45f2d0db721963f431be3c70e5a851dbe8ed2ba253c6da66"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
