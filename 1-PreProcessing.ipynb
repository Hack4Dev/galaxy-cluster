{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "adbff74c-bad7-48db-8c06-46c8ae5d06e7",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a6e5406-2ec0-42b3-bcef-8c3856cfb7ac",
   "metadata": {},
   "source": [
    "Hello, in this notebook we will try to download and pre-process astronomical data. The data contains 10,000 images of galaxies (either 3x64x64 or 3x224x224), confidently labelled by Galaxy Zoo volunteers as belonging to one of four morphology classes.\n",
    "\n",
    "GalaxyMNIST has four classes: smooth and round, smooth and cigar-shaped, edge-on-disk, and unbarred spiral. The galaxies are selected from Galaxy Zoo DECaLS Campaign A (GZD-A). \n",
    "\n",
    "At least 17 people must have been asked the necessary questions, and at least half of them must have answered with the given class. The class labels are therefore much more confident than from, for example, simply labelling with the most common answer to some question.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e74ab73-1be1-4063-b552-dc26466d6390",
   "metadata": {},
   "source": [
    "### Downloading the data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7505e73e-8fe3-4f89-9299-168c52974f4a",
   "metadata": {},
   "source": [
    "First, let us call the python script that will let us download the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7c0b7a79-6210-47e9-a88e-050230bae66c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_import.galaxy_mnist import GalaxyMNISTHighrez"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f0a8f9b-705a-4289-a0a3-5f953f3bcad6",
   "metadata": {},
   "source": [
    "'GalaxyMNISTHighrez' class has the follwing attribuits: \n",
    " - `root`: Specifing the dir to download the data\n",
    " - `download:` A boolean value, `True` to download the images\n",
    " - `train:` A boolean value, `True` to assign the just the training data, `False` will assgin just the testing data. \n",
    "   - `Notice:` The data has a fixed 80/20 train/test division."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b0e526b1-fa23-4b61-be7f-e0b69f2fe157",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for the training data\n",
    "dataset_train = GalaxyMNISTHighrez(\n",
    "    root='data_import/data',\n",
    "    download=True,\n",
    "    train=True  # by default, or False for canonical test set\n",
    ")\n",
    "# for the testing data\n",
    "dataset_test = GalaxyMNISTHighrez(\n",
    "    root='data_import/data',\n",
    "    download=True,\n",
    "    train=False  # by default, or False for canonical test set\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c67448b-a84d-4d3b-8c20-4be1c8707f81",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0811f16c-41f5-4576-8346-489b81daeaf5",
   "metadata": {},
   "source": [
    "### Reading and Visualising the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee8bd2ee-cda3-4eea-a685-45ea0b6ebd7c",
   "metadata": {},
   "source": [
    "first, let us read inputs `images` and outputs `labels` into two seperate variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3f1681f5-5382-4179-b0f1-b8932018c8e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "images_train = dataset_train.data\n",
    "labels_train = dataset_train.targets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afc89ec2-cfed-4756-b595-4ab69eb1bb56",
   "metadata": {},
   "source": [
    "let us check the shape of the two datasets (traning, and testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d453cced-95bd-498a-acc8-83da58636e78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the input (training) torch.Size([8000, 3, 224, 224]), type: torch.uint8\n",
      "Shape of the output (training) torch.Size([8000]), type: torch.int64\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape of the input (training) \"+str(images_train.shape)+ \", type: \"+ str(images_train.dtype))\n",
    "print(\"Shape of the output (training) \"+str(labels_train.shape)+ \", type: \"+ str(labels_train.dtype))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9453e0f1-96c5-4fc6-8d7c-98447cf9893d",
   "metadata": {},
   "source": [
    "we notice the following:\n",
    " 1. The input data has 8000 samples with 3 channels, which stands for `rgb` colors, where each sample has a size of 224\n",
    " 2. the output is just one dimnsional array, which contains the lables of the samples."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f52a7bbd-b5d3-4fe3-b8f2-6d62d667dacb",
   "metadata": {},
   "source": [
    "**Exersice1:**\n",
    "Store the testing set inputs and outputs into two diffrint variables, and display thier shape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4a886e8a-9fab-4d24-8011-c74372955262",
   "metadata": {},
   "outputs": [],
   "source": [
    "### -- Code here --\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d970d19-5d8b-4624-b037-f01619086d0e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gal_ker",
   "language": "python",
   "name": "gal_ker"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
